{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the diamond outputs for gene abundances analysis (metagenomic and metatranscriptomic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene='nifH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diamond_parse(diamond_path, column1='perc_id', cutoff1= 95, column2='length', cutoff2=30):\n",
    "    \"\"\"\n",
    "    This function is directed to a diamond_path, which refers to all the diamond.out files in a folder \n",
    "    We read it in, adding in column names, and filter the columns perc_id and length based on designated thresholds.\n",
    "    Here we use 95% perc_id and 30 amino acids in length (200 residues/3 = 66 amino acids *50%)\n",
    "    Then we groupby the subject_sequence in order to get the number of reads that mapped onto a particular protein id (k-id)\n",
    "    We normalize these counts to account for \"multimapping\"reads, that is, when our ERR query_sequence mapped to several subject_sequences, or protein k-ids, given highly conserved regions.\n",
    "    These .csv files are output with basename of the ERR file and \"norm_subject_counts\"\n",
    "    \"\"\"\n",
    "    diamond_files=glob.glob(diamond_path)\n",
    "    for filename in diamond_files:\n",
    "        filter_df=[]\n",
    "        open(filename)\n",
    "        base=os.path.basename(filename).replace(\".diamond.out\",\"\")\n",
    "        if os.stat(filename).st_size == 0:\n",
    "            pass\n",
    "        df=pd.read_csv(filename, sep='\\t', header=None)\n",
    "        df.columns=['query_sequence','subject_sequence','perc_id','length','mismatch','gap_open','query_start','query_end','subject_start','subject_end','e_value','bit_score']\n",
    "        filter_df=df[(df[column1]>=cutoff1) & (df[column2]>=cutoff2)]\n",
    "        count_map=filter_df.groupby(['query_sequence','subject_sequence'])['perc_id'].count().unstack().fillna(0) #gives us 1 or 0 presence/absence for each k-id or subject (along x axis) for each ERR or query_sequence (y-axis)\n",
    "        count_map_sum=count_map.sum(axis=1)#flips orientation and sums \n",
    "        df_norm_counts= pd.DataFrame(count_map.divide(count_map_sum, axis=0).sum(axis=0)) #divide to get our factor for normalizing\n",
    "        df_norm_counts.columns= [os.path.basename(base).replace(\".diamond.out\",\"\")]\n",
    "        df_norm_counts.to_csv(os.path.join(output_folder, base+\"_norm_subject_counts.csv\")) #our second output to .csv, for normalizing by the number of protein k-ids an ERR query_sequence matched to \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 12 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fc6a5411ef12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmetaG_diamond_folder\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diamond_mapping'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PRJEB4352/*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#note the two PRJ files, 4352 is metagenome and 6609 is metatranscriptomic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdiamond_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetaG_diamond_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-63216398ab64>\u001b[0m in \u001b[0;36mdiamond_parse\u001b[0;34m(diamond_path, column1, cutoff1, column2, cutoff2)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query_sequence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_sequence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'perc_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mismatch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gap_open'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'query_start'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'query_end'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_start'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_end'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'e_value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bit_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mfilter_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mcutoff1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mcutoff2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcount_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query_sequence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'perc_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#gives us 1 or 0 presence/absence for each k-id or subject (along x axis) for each ERR or query_sequence (y-axis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5078\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5079\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5080\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5081\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5082\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    153\u001b[0m             raise ValueError(\n\u001b[1;32m    154\u001b[0m                 \u001b[0;34m'Length mismatch: Expected axis has {old} elements, new '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 'values have {new} elements'.format(old=old_len, new=new_len))\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 12 elements"
     ]
    }
   ],
   "source": [
    "output_folder = os.path.join(\"/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping\", gene,'metaG_abundance_outputs') \n",
    "#output folder is for metaG abundance data\n",
    "\n",
    "metaG_diamond_folder= os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping', gene, 'PRJEB4352/*')\n",
    "#note the two PRJ files, 4352 is metagenome and 6609 is metatranscriptomic\n",
    "\n",
    "diamond_parse(metaG_diamond_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-09ba6c03b043>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diamond_mapping'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'metaT_abundance_outputs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# run function with output for metaT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmetaT_diamond_folder\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diamond_mapping'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PRJEB6609/*'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#metaT for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiamond_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetaT_diamond_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-63216398ab64>\u001b[0m in \u001b[0;36mdiamond_parse\u001b[0;34m(diamond_path, column1, cutoff1, column2, cutoff2)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query_sequence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_sequence'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'perc_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mismatch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gap_open'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'query_start'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'query_end'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_start'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'subject_end'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'e_value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bit_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mfilter_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mcutoff1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mcutoff2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/jupyter/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output_folder= os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene,'metaT_abundance_outputs')\n",
    "#run function with output for metatranscritomic data\n",
    "\n",
    "metaT_diamond_folder= os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping', gene, 'PRJEB6609/*') \n",
    "#location of diamond outputs for this gene for metatranscriptomic data\n",
    "\n",
    "diamond_parse(metaT_diamond_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in all the intermediate files for metaG abundance data and concatenate\n",
    "from functools import reduce\n",
    "metaG_abundance_path = os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene, 'metaG_abundance_outputs/')\n",
    "filenames = glob.glob(metaG_abundance_path + \"/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "# Concatenate all data into one DataFrame\n",
    "metaG_abundance = reduce(lambda x, y: pd.merge(x, y, on='subject_sequence', how='outer'), dfs)\n",
    "metaG_abundance=metaG_abundance.set_index('subject_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in all the intermediate files for metaT abundance data and concatenate\n",
    "from functools import reduce\n",
    "metaT_abundance_path = os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene,'metaT_abundance_outputs/')\n",
    "filenames = glob.glob(metaT_abundance_path + \"/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "    \n",
    "# Concatenate all data into one DataFrame\n",
    "metaT_abundance = reduce(lambda x, y: pd.merge(x, y, on='subject_sequence', how='outer'), dfs)\n",
    "metaT_abundance=metaT_abundance.set_index('subject_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaG_abundance=metaG_abundance.fillna(0)\n",
    "metaG_abundance.to_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene, gene+'_metaG_PRJEB4352_95_raw_abundance_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaG_95_raw= pd.read_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene,gene+'_metaG_PRJEB4352_95_raw_abundance_table.csv'), index_col='subject_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaG_wenv=pd.read_csv('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/PANGEA_Merged_TARA.csv', index_col='run_accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaG_RPM=metaG_95_raw/(metaG_wenv.read_count/1000000)\n",
    "metaG_RPM_dropna=metaG_RPM.dropna(how='any', axis=1)  #drop columns that were na (meaning we didn't have that ERR)\n",
    "\n",
    "#get our sequence lengths for normalization (RPKM) from the fasta file with the sequences clustered at 98% similar\n",
    "sequence_lengths = []\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(gene+'_clust_98'), \"fasta\") :\n",
    "    subject_sequence = record.id\n",
    "    length = len(record.seq)\n",
    "    sequence_lengths.append((subject_sequence, length))\n",
    "    \n",
    "sequence_lengths_df=pd.DataFrame(sequence_lengths, columns=('subject_sequence','length')) \n",
    "\n",
    "#here we use our sequence_lengths_df to normalize by gene length giving us RPKM for abundances. \n",
    "metaG_RPM_with_length= metaG_RPM_dropna.merge(sequence_lengths_df, left_on='subject_sequence', right_on='subject_sequence').set_index('subject_sequence')\n",
    "RPKM_metaG= metaG_RPM_with_length.iloc[:, 1:-1].divide(metaG_RPM_with_length.iloc[:,-1], axis = 'rows')\n",
    "RPKM_metaG.to_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene, gene+'_RPKM_metaG_PRJEB4352_95_abundance_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metatranscriptomic metadata\n",
    "metaT_wenv=pd.read_csv('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/PANGEA_Merged_TARA_metaT.csv', index_col='run_accession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaT_abundance=metaT_abundance.fillna(0)\n",
    "metaT_abundance.to_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping', gene, gene+'_metaT_PRJEB6609_95_raw_abundance_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metaT_95_raw= pd.read_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping', gene, gene+'_metaT_PRJEB6609_95_raw_abundance_table.csv'), index_col='subject_sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaT_RPM=metaT_95_raw/(metaT_wenv.read_count/1000000)\n",
    "metaT_RPM_dropna=metaT_RPM.dropna(how='any', axis=1)  #drop columns that were na (meaning we didn't have that ERR)\n",
    "\n",
    "#get our sequence lengths for normalization (RPKM) from the fasta file withthe clustered 98 seqs\n",
    "\n",
    "sequence_lengths = []\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(gene+'_clust_98'), \"fasta\") :\n",
    "    subject_sequence = record.id\n",
    "    length = len(record.seq)\n",
    "    sequence_lengths.append((subject_sequence, length))\n",
    "    \n",
    "sequence_lengths_df=pd.DataFrame(sequence_lengths, columns=('subject_sequence','length')) \n",
    "\n",
    "#here we use our sequence_lengths_df to normalize by gene length giving us RPKM for abundances.\n",
    "metaT_RPM_with_length= metaT_RPM_dropna.merge(sequence_lengths_df, left_on='subject_sequence', right_on='subject_sequence').set_index('subject_sequence')\n",
    "RPKM_metaT= metaT_RPM_with_length.iloc[:, 1:-1].divide(metaT_RPM_with_length.iloc[:,-1], axis = 'rows')\n",
    "RPKM_metaT.to_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping', gene, gene+'_RPKM_metaT_PRJEB6609_95_abundance_table.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df of our normalized counts by sample and some environmental data for metaG\n",
    "metaG_abundance_sum=RPKM_metaG.sum()\n",
    "metaG_abundance_frame=metaG_abundance_sum.to_frame(name='gene_abundance')\n",
    "metaG_abundance_wenv=metaG_abundance_frame.merge(metaG_wenv, left_index=True, right_on='run_accession')\n",
    "metaG_abundance_wenv[\"Depth\"]=metaG_abundance_wenv['Sample material'].str.split(\"_\").str[2]\n",
    "metaG_abundance_wenv[\"Size_fraction\"]=metaG_abundance_wenv['Sample material'].str.split(\"_\").str[3]\n",
    "metaG_abundance_wenv[\"Size_fraction_group\"]=metaG_abundance_wenv['Size_fraction'].replace('0.8->','0.8-5').replace('0.8-3','0.8-5').replace('0.8-20','5-20').replace('3->','0.8-5').replace('0.22-3','0.8-5')\n",
    "metaG_abundance_wenv.to_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene, gene+'_metaG_abundance_wenv_table.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a df of our normalized counts by sample and some environmental data for metaT\n",
    "\n",
    "metaT_abundance_sum=RPKM_metaT.sum()\n",
    "metaT_abundance_frame=metaT_abundance_sum.to_frame(name='gene_abundance')\n",
    "metaT_abundance_wenv=metaT_abundance_frame.merge(metaT_wenv, left_index=True, right_on='run_accession')\n",
    "metaT_abundance_wenv[\"Depth\"]=metaT_abundance_wenv['Sample material'].str.split(\"_\").str[2]\n",
    "metaT_abundance_wenv[\"Size_fraction\"]=metaT_abundance_wenv['Sample material'].str.split(\"_\").str[3]\n",
    "metaT_abundance_wenv[\"Size_fraction_group\"]=metaT_abundance_wenv['Size_fraction'].replace('0.8->','0.8-5').replace('0.8-3','0.8-5').replace('0.8-20','5-20').replace('3->','0.8-5').replace('0.22-3','0.8-5')\n",
    "metaT_abundance_wenv.to_csv(os.path.join('/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/gene_abundances/diamond_mapping',gene, gene+'_metaT_abundance_wenv_table.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
