{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NifH Gene-Finder Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook provides a standard workflow for downstream analysis of the result outputs from executing the gene-finder snakemake file which builds an alignment profile from our reference gene alignment and uses HMMER searches to compare it against the Tara oceans metagenome assemblies for the larger size fractions.\n",
    "\n",
    "Current functions: \n",
    "1. evalueglob: concatenates all the evalue tables output from our hmmsearch results for a given gene into one data frame with sample id; output is a data frame saved to csv\n",
    "2. threshold_cutoff: takes only evalues below a certain threshold value and outputs a data frame for those sequence hits. Threshold cutoff may need to be designated using manual checking of sequences against NCBI protein database using BLAST.\n",
    "3. getfasta2: extracts the fasta sequences which correspond to hits meeting the threshold above and puts them into an output fasta file.\n",
    "4. filter_length : filter sequences by a desired length and output a fasta file of the longer sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANT OBJECT DEFINITIONS (can be changed as desired)\n",
    "\n",
    "#gene name can be edited for each gene of interest \n",
    "gene= \"nifH\"\n",
    "\n",
    "#evalue_tables_path is the path to the gene specific set of all the evalue table files output from hmmsearch done with snakemake\n",
    "evalue_tables_path=\"/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/hmm_results/nifH/*.tab\"\n",
    "\n",
    "#proteinpath is for the prodigal_proteins data folder\n",
    "proteinpath= \"/vortexfs1/omics/alexander/lblum/tara_gene_finder/data/prodigal_proteins\"\n",
    "\n",
    "#output_folder will be a gene-specific folder for outputs from jupyter notebook analysis of results from the snakemake hmmsearches \n",
    "output_folder= \"/vortexfs1/omics/alexander/lblum/tara_gene_finder/jupyter_notebooks/outputs/nifH/\"\n",
    "\n",
    "#extracted_hits_path directs desired gene sequences to a fasta file for the iterative alignment/ gene-finder search\n",
    "extracted_hits_path= os.path.join(output_folder,gene+\"_extracted_hits.fasta\")\n",
    "\n",
    "#location of the gene-specific set of hmm_results, in this case nifH\n",
    "hits_results_path= \"/vortexfs1/omics/alexander/lblum/tara_gene_finder/results/hmm_results/nifH/*.faa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputing our sample info file which contains all the assigned size fractions\n",
    "sample_info=pd.read_csv('/vortexfs1/omics/alexander/lblum/tara_gene_finder/data/metadata/SampleList_ForAssembly_metaG_python.txt', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalueglob(globfolder):\n",
    "    \"\"\"This function will go through all of the eval table files in a directory \n",
    "    And combine them into a a new data frame with the sample id listed\n",
    "    input is results .eval.tab files and output should be for nifH to a new output folder\n",
    "    \n",
    "    *globfolder selects all the eval.tab files in the results folder for the gene of interest using a wild card*\n",
    "    *gene needs to be defined at the top of the script as nifH or another gene*\n",
    "    \n",
    "    \"\"\"\n",
    "    data = [] # pd.concat combines list of data frames; #sep='\\t' for formatting tab separated values\n",
    "    eval_files = glob.glob(globfolder)\n",
    "    for tab in eval_files:\n",
    "        frame= pd.read_csv(tab, sep='\\t')\n",
    "        frame['sample_id'] = os.path.basename(tab).replace(\".eval.tab\",\"\")\n",
    "        #create new column with base name \n",
    "        data.append(frame)\n",
    "\n",
    "    eval_table = pd.concat(data, ignore_index=True) \n",
    "    eval_table.to_csv(os.path.join(output_folder,gene+\"_eval_table.csv\"))\n",
    "    return(eval_table)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_cutoff(df, column= 'e-value', evalue= 10 **-40):\n",
    "    \"\"\"\n",
    "    This function will take our concatenated evalue table and filter it based on a given threshold cutoff; \n",
    "    column and evalue are set to default parameters. E-value threshold can be modified as needed.\n",
    "    \"\"\"\n",
    "    outdf= df[df[column] <= evalue]\n",
    "    return(outdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfasta2(hitsfolder, dataframe):\n",
    "    \"\"\"\n",
    "    This function is meant to more efficiently extract sequences from our hits.faa results files of the snakemake hmmsearches\n",
    "    based on the threshold set in the threshold_cutoff function producing the threshold_hits data table with contig_id.\n",
    "    produces a single fasta file with all the sequences meeting the threshold, called gene_extracted_hits_test.fasta.\n",
    "    hitsfolder is defined at top (hits_resutls_path for all the hits.faa files in results)\n",
    "    dataframe is threshold hits\n",
    "    Uses glob and SeqIO are imported at the top of the script\n",
    "    \"\"\"\n",
    "    files_list = glob.glob(hitsfolder) #glob through all the files in hitsfolder, which we define to be the .hits.faa resulting from snakemake hmmsearches and stored in results folder\n",
    "\n",
    "    output_handle = open(os.path.join(output_folder,gene+\"_extracted_hits.fasta\"), \"w\") #append this extracted_hits_test file\n",
    "\n",
    "    for file_name in files_list:\n",
    "        records= SeqIO.index(file_name,\"fasta\") \n",
    "\n",
    "        for i in dataframe[\"contig_id\"]:  #call on the column \"contig_id\" from dataframe (threshold_hits) and if that contig_id shows up in the records(which index the fasta file) the sequence is added\n",
    "            if i in records:\n",
    "                SeqIO.write(records[i], output_handle, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " def filter_length(filename):\n",
    "    \"\"\"\n",
    "    This function uses SeqIO from Biopython: (from Bio import SeqIO) already at top of script\n",
    "    It will take the output file of extracted_hits.fasta from getfasta function used in the last step, or another fasta file,\n",
    "    and filter for only sequences of a certain length.\n",
    "    It will save the sequences that meet the length requirement as a new fasta file called gene, \"_length_filtered_hits.fasta\" in the outputs folder\n",
    "    \"\"\"\n",
    "    long_sequences = []\n",
    "    input_handle=open(filename) #input_handle will correspond to the file defined in extracted_hits_path at the top of the script, corresponding to the output file from getfasta \n",
    "    output_handle = open(os.path.join(output_folder,gene+\"_length_filtered_hits.fasta\"), \"w\") #able to open for writing file #not sure about os.path.join(output_folder,gene+\"_filtered_hits.fasta\")\n",
    "    \n",
    "    for record in SeqIO.parse(input_handle, \"fasta\") :\n",
    "        if len(record.seq) >= 160 :\n",
    "            # this adds the record if it meets the length requirement\n",
    "            long_sequences.append(record) #appends long_sequences object to contain the records that match the condition in the for loop, meeting the length requirement\n",
    " \n",
    "    print (\"Found long sequences\")\n",
    "\n",
    "    SeqIO.write(long_sequences, output_handle, \"fasta\")  #writes long_sequences into a fasta file directed to the output handle, defined to be in the output folder with a new name of \"_length_filtered_hits.fasta\"\n",
    "    input_handle.close()\n",
    "    output_handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evalue_tables_path defined at top of jupyter notebook\n",
    "#call evalueglob with the path to all the tables to create a .csv of all our concatenated evalue tables with sample name.\n",
    "#you need to define the return as eval_table so that when we call it in our next function the output is already defined (otherwise just writes to csv)\n",
    "eval_table=evalueglob(evalue_tables_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#threshhold_hits = full_eval_table[full_eval_table['e-value'] <= 1 * 10 **-40]   \n",
    "#used the above to model the function below which creates a data frame of threshold cutoff hits\n",
    "#reference column either with .name or ['name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_hits=threshold_cutoff(eval_table, evalue= 10 **-40)\n",
    "#here we call our new threshold_cutoff function and have to provide a data frame (which is eval_table, as outputed by the evalueglob function)\n",
    "#we can specify a different evalue than is set\n",
    "#we call the output threshold_hits and use this for our summary table and for our getfasta2 function later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_hits.to_csv(os.path.join(output_folder,gene+\"_threshold_hits_table.csv\"), index=False)\n",
    "#this table will be needed later for searching within MAGS, as it links sequence id to sample id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_cutoff = eval_table[(eval_table['e-value'] >= 1 * 10 **-43) & (eval_table['e-value'] <= 1 * 10 **-30)]\n",
    "#manually check sequences using BLAST around the threshold to ensure reliable filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table = pd.DataFrame(data=eval_table['sample_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_info read in at top\n",
    "#merge the sample info to the threshold hits table\n",
    "threshold_with_info= threshold_hits.merge(sample_info, left_on='sample_id', right_on='Assembly_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "getfasta2(hits_results_path, threshold_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found long sequences\n"
     ]
    }
   ],
   "source": [
    "#here we use the filter_length function by inputing the file containing extracted_hits that met the e-value cut off\n",
    "#we take the sequences that meet the length requirement and save those to a new length_filtered_hits.fasta file.\n",
    "###if __name__==\"__main__\":  #what does this do??#\n",
    "filter_length(extracted_hits_path)\n",
    "    #path defined at the top of script and guides to the location of the extracted_hits.fasta file in outputs folder for this gene which was made with the getfasta function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
